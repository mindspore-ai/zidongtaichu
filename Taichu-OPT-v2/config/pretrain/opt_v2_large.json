{
  "model_config": "config/pretrain/model_large.json",
  "output_dir": "output/opt_v2_large",
  "use_large_data": true,
  "train_batch_size": 48,
  "val_batch_size": 1,
  "full_batch": false,
  "is_two": true,
  "learning_rate": 5e-5,
  "start_learning_rate": 5e-5,
  "end_learning_rate": 1e-6,
  "optim": "adamw",
  "betas": [
    0.9,
    0.98
  ],
  "dropout": 0.1,
  "weight_decay": 0.01,
  "grad_norm": 1.0,
  "warmup_steps": 10000,
  "decay_steps": 400000,
  "seed": 42,
  "ids_train_path": ["dataset/text/json_coco_train_zh_token.json"],
  "vocab_path": "dataset/text/ids_to_tokens_zh.json",
  "use_validate": false,
  "use_vit": true,
  "use_patch": true,
  "patch_size": 14,
  "image_size": 336,
  "embed_size": 512,
  "img_dim": 1024,
  "epoch": 10,
  "vit_ckpt_file": "",
  "train_datasets": [
    {
      "name": "open",
      "db": [
        "dataset/text"
      ],
      "img": [
        "dataset/image"
      ],
      "audio": [
        "dataset/audio"
      ],
      "tasks": [
        "itmTwo"
      ],
      "mix_ratio": [
        1
      ]
    }
  ],
  "ids_val_path": "/store1/xxzhu/text/flickr30k_test_zh_token.json",
  "val_datasets": [
    {
      "name": "open",
      "db": [
        "dataset/text"
      ],
      "img": [
        "dataset/image"
      ],
      "audio": [
        "dataset/audio"
      ],
      "tasks": [
        "itmTwo"
      ]
    }
  ]
}
